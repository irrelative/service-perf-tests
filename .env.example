# Copy this file to `.env` and fill in your values.
# These are read by both s3_orch_bench.py and s3_sqs_choreography_bench.py via python-dotenv.

# Required: S3 bucket to store benchmark payloads
ORCH_BUCKET=your-s3-bucket-name

# Optional: S3 prefix under which runs will be created; the tool appends /<RUN_ID>
ORCH_PREFIX=orchestration-bench/runs

# Optional: SQS queue name prefix for choreography runs; queues are suffixed with the run id
ORCH_QUEUE_PREFIX=orchestration-bench-queue

# Number of steps in the chain
STEPS=5

# Payload size per step in megabytes
PAYLOAD_MB=50

# Serializer to use: json, json-gz, or pickle
SERIALIZER=json

# Whether to delete S3 payloads after a successful run: true/false
CLEANUP=false

# Whether to delete ephemeral SQS queues after a successful choreography run: true/false
CLEANUP_QUEUES=true

# Optional AWS configuration (leave blank to use SDK defaults/instance role)
AWS_PROFILE=
AWS_REGION=
